<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A better way to visualize Decision Trees with the dtreeviz library | Breaking the Jargons</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A better way to visualize Decision Trees with the dtreeviz library" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An open-source package for decision tree visualization and model interpretation" />
<meta property="og:description" content="An open-source package for decision tree visualization and model interpretation" />
<link rel="canonical" href="https://parulnith.github.io/blog/machine%20learning/data%20visualization/2021/05/18/A-better-way-to-visualize-Decision-Trees-with-the-dtreeviz-library.html" />
<meta property="og:url" content="https://parulnith.github.io/blog/machine%20learning/data%20visualization/2021/05/18/A-better-way-to-visualize-Decision-Trees-with-the-dtreeviz-library.html" />
<meta property="og:site_name" content="Breaking the Jargons" />
<meta property="og:image" content="https://parulnith.github.io/blog/images/2021-05-18-%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library/0.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-18T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://parulnith.github.io/blog/machine%20learning/data%20visualization/2021/05/18/A-better-way-to-visualize-Decision-Trees-with-the-dtreeviz-library.html","@type":"BlogPosting","headline":"A better way to visualize Decision Trees with the dtreeviz library","dateModified":"2021-05-18T00:00:00-05:00","datePublished":"2021-05-18T00:00:00-05:00","image":"https://parulnith.github.io/blog/images/2021-05-18-%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library/0.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://parulnith.github.io/blog/machine%20learning/data%20visualization/2021/05/18/A-better-way-to-visualize-Decision-Trees-with-the-dtreeviz-library.html"},"description":"An open-source package for decision tree visualization and model interpretation","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://parulnith.github.io/blog/feed.xml" title="Breaking the Jargons" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Breaking the Jargons</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Categories</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A better way to visualize Decision Trees with the dtreeviz library</h1><p class="page-description">An open-source package for decision tree visualization and model interpretation</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-18T00:00:00-05:00" itemprop="datePublished">
        May 18, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Machine Learning">Machine Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Data Visualization">Data Visualization</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#dtreeviz-library-for-visualizing-tree-based-models">dtreeviz library for visualizing tree-based models</a></li>
<li class="toc-entry toc-h2"><a href="#superior-visualizations-by-dtreeviz">Superior visualizations by dtreeviz</a>
<ul>
<li class="toc-entry toc-h3"><a href="#understanding-decision-trees">Understanding Decision Trees</a></li>
<li class="toc-entry toc-h3"><a href="#my-notes-on-decision-trees-from-the-course--analytics-edge">My notes on Decision Trees from the course — Analytics Edge</a></li>
<li class="toc-entry toc-h3"><a href="#dataset">Dataset</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#visualizations">Visualizations</a>
<ul>
<li class="toc-entry toc-h3"><a href="#regression-decision-tree">Regression decision tree</a></li>
<li class="toc-entry toc-h3"><a href="#classification-decision-tree">Classification decision tree</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#customizations">Customizations</a>
<ul>
<li class="toc-entry toc-h3"><a href="#scaling-the-image">Scaling the image</a></li>
<li class="toc-entry toc-h3"><a href="#trees-with-a-left-to-right-alignment">Trees with a left to right alignment</a></li>
<li class="toc-entry toc-h3"><a href="#prediction-path-of-a-single-observation">Prediction path of a single observation</a></li>
<li class="toc-entry toc-h3"><a href="#saving-the-image">Saving the image</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
<li class="toc-entry toc-h2"><a href="#references-and-further-reading">References and further reading:</a></li>
</ul><p>It is rightly said that a picture is worth a thousand words. This axiom is equally applicable for machine learning models. If one can visualize and interpret the result, it instills more confidence in the model’s predictions. Visualizing how a machine learning model works also makes it possible to explain the results to people with less or no machine learning skills. Scikit-learn library inherently comes with the plotting capability for decision trees via the  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html">sklearn.tree.export_graphviz</a> function. However, there are some inconsistencies with the default option. This article will look at an alternative called  <a href="https://github.com/parrt/dtreeviz">dtreeviz</a>  that renders better looking and intuitive visualizations while offering greater interpretability options.</p>

<h2 id="dtreeviz-library-for-visualizing-tree-based-models">
<a class="anchor" href="#dtreeviz-library-for-visualizing-tree-based-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>dtreeviz library for visualizing tree-based models</h2>

<p>The  <strong>dtreeviz</strong>  is a python library for decision tree visualization and model interpretation. According to the information available on its  <a href="https://github.com/parrt/dtreeviz">Github repo</a>, the library currently supports  <a href="https://scikit-learn.org/stable">scikit-learn</a>,  <a href="https://xgboost.readthedocs.io/en/latest">XGBoost</a>,  <a href="https://spark.apache.org/mllib/">Spark MLlib</a>, and  <a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a>  trees.</p>

<p>Here is a visual comparison of the visualization generated from default scikit-learn and that from dtreeviz on the famous  <a href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009">wine quality dataset</a>. The dataset includes 178 instances and 13 numeric predictive attributes. Each data point can belong to one of the three classes named class_0, class_1, and class_2.</p>

<p><img src="./images/2021-05-18-A%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library/comparison.png" alt="Alt Text"></p>

<p><sub>Visual comparison of the visualization generated from default scikit-learn(Left) and that from dtreeviz(Right) on the famous  <a href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009">wine quality dataset</a></sub></p>

<p>As is evident from the pictures above, the figure on the right delivers far more information than its counterpart on the left. There are some apparent issues with the default scikit learn visualization, for instance:</p>

<ul>
  <li>It is not immediately clear as to what the different colors represent.</li>
  <li>There are no legends for the target class.</li>
  <li>The visualization returns the count of the samples, and it isn’t easy to visualize the distributions.</li>
  <li>The size of every decision node is the same regardless of the number of samples.</li>
</ul>

<p>The dtreeviz library plugs in these loopholes to offer a clear and more comprehensible picture. Here is what the authors have to say:</p>

<blockquote>
  <p>The visualizations are inspired by an educational animation by  <a href="http://www.r2d3.us/">R2D3</a>;  <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A visual introduction to machine learning</a>. With  <code class="language-plaintext highlighter-rouge">dtreeviz</code>, you can visualize how the feature space is split up at decision nodes, how the training samples get distributed in leaf nodes, how the tree makes predictions for a specific observation and more. These operations are critical to for understanding how classification or regression decision trees work.</p>
</blockquote>

<p>We’ll see how the dtreeviz scores over the other visualization libraries through some common examples in the following sections. For the  <strong>installation instructions,</strong>  please refer to the official <a href="https://github.com/parrt/dtreeviz#install">Github page</a>. It can be installed with  <code class="language-plaintext highlighter-rouge">pip install dtreeviz but</code>requires  <code class="language-plaintext highlighter-rouge">graphviz</code>  to be pre-installed.</p>

<h2 id="superior-visualizations-by-dtreeviz">
<a class="anchor" href="#superior-visualizations-by-dtreeviz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Superior visualizations by dtreeviz</h2>

<p>Before visualizing a decision tree, it is also essential to understand how it works. A Decision Tree is a supervised learning predictive model that uses a set of binary rules to calculate a target value. It can be used both for regression as well as classification tasks. Decision trees have three main parts:</p>

<ul>
  <li>
<strong>Root Node:</strong> The node that performs the first split.</li>
  <li>
<strong>Terminal Nodes/Leaf node:</strong> Nodes that predict the outcome.</li>
  <li>
<strong>Branches:</strong> arrows connecting nodes, showing the flow from question to answer.</li>
</ul>

<p>The algorithm of the decision tree models works by repeatedly partitioning the data into multiple sub-spaces so that the outcomes in each final sub-space are as homogeneous as possible. This approach is technically called  <em>recursive partitioning</em>. The algorithm tries to split the data into subsets so that each subgroup is as pure or  <strong>homogeneous</strong>  as possible.</p>

<p>The above excerpt has been taken from an article I wrote on understanding decision trees. This article goes deeper into explaining how the algorithm typically makes a decision.</p>

<p><img src="https://medium.com/analytics-vidhya/a-guide-to-machine-learning-in-r-for-beginners-decision-trees-c24dfd490abb" alt="Alt text"></p>

<h3 id="understanding-decision-trees">
<a class="anchor" href="#understanding-decision-trees" aria-hidden="true"><span class="octicon octicon-link"></span></a>Understanding Decision Trees</h3>

<h3 id="my-notes-on-decision-trees-from-the-course--analytics-edge">
<a class="anchor" href="#my-notes-on-decision-trees-from-the-course--analytics-edge" aria-hidden="true"><span class="octicon octicon-link"></span></a>My notes on Decision Trees from the course — Analytics Edge</h3>

<p>Now let’s get back to the dtreeviz library and plot a few of them using the wine data mentioned above.</p>

<h3 id="dataset">
<a class="anchor" href="#dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset</h3>

<p>We’ll be using the famous red wine dataset from the  <a href="https://archive.ics.uci.edu/ml/datasets/wine+quality"><strong>Wine Quality Data Set</strong></a><strong>.</strong> The dataset consists of few physicochemical tests related to the red variant of the Portuguese “Vinho Verde” wine. The goal is to model wine quality based on these tests. Since this dataset can be viewed both as a classification and regression task, it is apt for our use case. We will not have to use separate datasets for demonstrating the classification and regression examples.</p>

<blockquote>
  <p><strong>Here is the</strong> <a href="https://nbviewer.jupyter.org/github/parulnith/Data-Science-Articles/blob/main/A%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library/A%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library.ipynb"><strong>nbviewer link</strong></a> <strong>to the notebook incase you want to follow along.</strong></p>
</blockquote>

<p>Let’s look at the first few rows of the dataset:</p>

<p><img src="https://miro.medium.com/max/1159/1*9_4BRH_RMVmkrYcTZHyh4A.png" alt="Alt text"></p>

<table>
  <tbody>
    <tr>
      <td>A glance at the dataset</td>
      <td>Image by Author</td>
    </tr>
  </tbody>
</table>

<p>The  <code class="language-plaintext highlighter-rouge">quality</code>  parameter refers to the wine quality and is a score between 0 and 10</p>

<p><img src="https://miro.medium.com/max/989/1*7lVBiek6NE6DopRxJ8Z9Ow.png" alt="Alt text"></p>

<h2 id="visualizations">
<a class="anchor" href="#visualizations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualizations</h2>

<p>Creating the features and target variables for ease.</p>

<p>features = wine.drop(‘quality’,axis=1)<br>
target = wine[‘quality’]</p>

<h3 id="regression-decision-tree">
<a class="anchor" href="#regression-decision-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression decision tree</h3>

<p>For the regression example, we’ll be predicting the  <code class="language-plaintext highlighter-rouge">quality</code>  of the wine.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> #Regression tree on Wine data
fig = plt.figure(figsize=(25,20))  
regr= tree.DecisionTreeRegressor(max_depth=3) regr.fit(features, target)viz = dtreeviz(regr,  
               features,  
               target,  
               target_name='wine quality',  
               feature_names=features.columns,  
               title="Wine data set regression",  
               fontname="Arial",  
               colors = {"title":"purple"},  
               scale=1.5)  
viz
</code></pre></div></div>

<p><img src="https://miro.medium.com/max/710/1*qzLs2IBAYSEJwycZ0rc7mg.png" alt="Alt text"></p>

<p><sub>Regression decision tree </sub></p>

<ul>
  <li>The horizontal dashed lines indicate the target mean for the left and right buckets in decision nodes;</li>
  <li>A vertical dashed line indicates the split point in feature space.</li>
  <li>The black wedge highlights the split point and identifies the exact split value.</li>
  <li>Leaf nodes indicate the target prediction (mean) with a dashed line.</li>
</ul>

<h3 id="classification-decision-tree">
<a class="anchor" href="#classification-decision-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classification decision tree</h3>

<p>For the classification example, we’ll predict the  <code class="language-plaintext highlighter-rouge">class</code>  of wine from the given six classes. Again the target here is the quality variable.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Classification tree on Wine datafig = plt.figure(figsize=(25,20))  
clf = tree.DecisionTreeClassifier(max_depth=3)clf.fit(features, target)# pick random X observation for demo  
#X = wine.data[np.random.randint(0, len(wine.data)),:]viz = dtreeviz(clf,  
               features,  
               target,  
               target_name='wine quality',  
               feature_names=features.columns,  
               title="Wine data set classification",  
               class_names=['5', '6', '7', '4', '8', '3'],  
               histtype='barstacked', # default   
               scale=1.2)  
viz
</code></pre></div></div>

<p><img src="https://miro.medium.com/max/783/1*uTuE2EtGgpG2VFMQZNKzkw.png" alt="Alt text"></p>

<p><sub>Classification tree on Wine data</sub></p>

<p>Unlike regressors, the target is a category for the classifiers. Therefore histograms are used to illustrate feature-target space. The stacked histograms might be challenging to read when the number of classes increases. In such cases, the  <code class="language-plaintext highlighter-rouge">histogram type</code>  parameter can be changed to  <code class="language-plaintext highlighter-rouge">bar</code>from  <code class="language-plaintext highlighter-rouge">barstacked,</code>  which is the default.</p>

<h2 id="customizations">
<a class="anchor" href="#customizations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Customizations</h2>

<p>The dtreeviz library also offers a bunch of customizations. I’ll showcase a few of them here:</p>

<h3 id="scaling-the-image">
<a class="anchor" href="#scaling-the-image" aria-hidden="true"><span class="octicon octicon-link"></span></a>Scaling the image</h3>

<p>The scale parameter can be used to scale the overall image.</p>

<h3 id="trees-with-a-left-to-right-alignment">
<a class="anchor" href="#trees-with-a-left-to-right-alignment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Trees with a left to right alignment</h3>

<p>The  <code class="language-plaintext highlighter-rouge">orientation</code>  parameter can be set to  <code class="language-plaintext highlighter-rouge">LR</code>  to display the trees from left to right rather than top-down</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fig = plt.figure(figsize=(25,20))  
clf = tree.DecisionTreeClassifier(max_depth=2)clf.fit(features, target)# pick random X observation for demo  
#X = wine.data[np.random.randint(0, len(wine.data)),:]viz = dtreeviz(clf,  
               features,  
               target,  
               target_name='wine quality',  
               feature_names=features.columns,  
               title="Wine data set classification",  
               class_names=['5', '6', '7', '4', '8', '3'],  
               **orientation='LR',**   
               scale=1.2)  
viz
</code></pre></div></div>

<p><img src="https://miro.medium.com/max/1294/1*NRK-fvUXv0C-F_ZJMqyGUw.png" alt="Alt text"></p>

<p><sub>Trees with left to right alignment </sub></p>

<h3 id="prediction-path-of-a-single-observation">
<a class="anchor" href="#prediction-path-of-a-single-observation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prediction path of a single observation</h3>

<p>The library also helps to isolate and understand which decision path is followed by a specific test observation. This is very useful in explaining the prediction or the results to others. For instance, let’s pick out a random sample from the dataset and traverse its decision path.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fig = plt.figure(figsize=(25,20))  
clf = tree.DecisionTreeClassifier(max_depth=3)clf.fit(features, target)**# pick random X observation for demo  
X = features.iloc[np.random.randint(0, len(features)),:].values**viz = dtreeviz(clf,  
               features,  
               target,  
               target_name='wine quality',  
               feature_names=features.columns,  
               title="Wine data set classification",  
               class_names=['5', '6', '7', '4', '8', '3'],  
               scale=1.3,  
               X=X)  
viz
</code></pre></div></div>

<p><img src="https://miro.medium.com/max/1323/1*6opIcPQ1sQOUFClZ6C_FzQ.png" alt="Alt text"></p>

<p><sub>Prediction path of a single observation </sub></p>

<h3 id="saving-the-image">
<a class="anchor" href="#saving-the-image" aria-hidden="true"><span class="octicon octicon-link"></span></a>Saving the image</h3>

<p>The output graph can be saved in an SVG format as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>viz.save_svg()
</code></pre></div></div>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<p>The dtreeviz library scores above others when it comes to plotting decision trees. The additional capability of making results interpretable is an excellent add-on; You can isolate a single data point and understand the prediction at a micro-level. This helps in better understanding a model’s predictions, and it also makes it easy to communicate the findings to others. What I have touched here is just the tip of the iceberg. The Github repository and the accompanying article by the author go into more detail, and I’ll highly recommend going through them. The links are in the reference section below.</p>

<h2 id="references-and-further-reading">
<a class="anchor" href="#references-and-further-reading" aria-hidden="true"><span class="octicon octicon-link"></span></a>References and further reading:</h2>

<ul>
  <li><a href="https://github.com/parrt/dtreeviz/">The official Github repository of dtreeviz.</a></li>
  <li>
<a href="https://explained.ai/decision-tree-viz/index.html#sec:1.4">How to visualize decision trees</a>  — A great read on decision tree visualization by creators of dtreeviz.</li>
  <li><a href="https://medium.com/analytics-vidhya/a-guide-to-machine-learning-in-r-for-beginners-decision-trees-c24dfd490abb">Understanding Decision Trees</a></li>
</ul>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="parulnith/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/machine%20learning/data%20visualization/2021/05/18/A-better-way-to-visualize-Decision-Trees-with-the-dtreeviz-library.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Posts on Machine Learning &amp; Data Science</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/parulnith" title="parulnith"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/parulpandeyindia" title="parulpandeyindia"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/pandeyparul" title="pandeyparul"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
