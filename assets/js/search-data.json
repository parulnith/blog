{
  
    
        "post0": {
            "title": "Use Colab more efficiently with these hacks",
            "content": "Colaboratory, or ‚ÄúColab‚Äù for short, are hosted Jupyter Notebooks by Google, They allow you to write and execute Python code via your browser. It is effortless to spin a Colab since it is directly integrated with your Google account. Colab provides free access to GPUs and TPUs, requires zero-configuration, and makes sharing of code seamless. . Colab has an interesting history. It initially started as an internal tool for data analysis at Google. However, later it was launched publically, and since then, many people have been using this tool to accomplish their machine learning tasks. Many students and people who do not have a GPU rely on colab for the free resources to run their machine learning experiments. . This article compiles some useful tips and hacks that I use to get my work done in Colab. I have tried to list most of the sources where I read them first. Hopefully, these tricks should help you to make the most of your Colab notebooks. . 1. Using local runtimes üñ• . Typically, Colab provides you with free GPU resources. However, If you have your own GPUs and still want to utilize the Colab UI, there is a way. You can use the Colab UI with a local runtime as follows: . . This way, you can execute code on your local hardware and access your local file system without leaving the Colab notebook. The official documentation goes deeper into the way it works. . . 2. Scratchpad üìÉ . Do you end up creating multiple Colab notebooks with names like ‚Äúuntitled 1.ipynb‚Äù and ‚Äúuntitled 2.ipynb‚Äù etc.? I guess most of us are sail in the same boat in this regard. If that‚Äôs the case, then the Cloud scratchpad notebook might be for you. The Cloud scratchpad is a special notebook available at the URL ‚Äî https://colab.research.google.com/notebooks/empty.ipynb that is not automatically saved to your drive account. It is great for experimentation or nontrivial work and doesn‚Äôt take space in Google drive. . . . 3. Open GitHub Jupyter Notebooks directly in Colab üìñ . Colab notebooks are designed in a way that they can easily integrate with GitHub. This means you can both load and save Colab notebooks to GitHub, directly. There is a handy way to do that, thanks to Seungjae Ryan Lee. . When you‚Äôre on a notebook on GitHub which you want to open in Colab, replace github with githubtocolab in the URL, leaving everything else untouched. This opens the same notebook in Colab. . . . 4. Get Notified of completed cell executions üîî . Colab can notify you of completed executions even if you switch to another tab, window, or application. You can enable it via Tools ‚Üí Settings ‚Üí Site ‚Üí Show desktop notifications (and allow browser notifications once prompted) to check it out. . . Here is a demo of how the notification appears even if you navigate to another tab. . . Additional Tip . Do you want this same functionality in your Jupyter Notebooks as well ? Well, I have you covered. You can also enable notifications in your Jupyter notebooks for cell completion. For details you can read a blog that I wrote on the same topic - Enabling notifications in your Jupyter notebooks for cell completion . . 5. Search for all notebooks in drive üîç . Do you want to search for a specific Colab notebook in the drive? Navigate to the Drive search box and add : . application/vnd.google.colaboratory . This will list all the Colab notebooks in your Google Drive. Additionally, you can also specify the title and ownership of a specific notebook. For instance, if I want to search for a notebook created by me, having ‚ÄòTransfer‚Äô in its title, I would mention the following: . . . 6. Kaggle Datasets into Google Colab üèÖ . If you are on a budget and have exhausted your GPU resources quota on Kaggle, this hack might come as a respite for you. It is possible to download any dataset seamlessly from Kaggle onto your Colab infrastructure. Here is what you need to do: . Download your Kaggle API Token : | . . On clicking the. ‚ÄòCreate New API Token‚Äô tab, a kaggle.json file will be generated that contains your API token. Create a folder named Kaggle in your Google Drive and store the kaggle.json file in it. . . Mount Drive in Colab Notebook | . . Provide the config path to kaggle.json and change the current working directory . import os os.environ[‚ÄòKAGGLE_CONFIG_DIR‚Äô] = ‚Äú/content/drive/My Drive/Kaggle‚Äù . %cd /content/drive/MyDrive/Kaggle . | Copy the API of the dataset to be downloaded. . | . For standard datasets, the API can be accessed as follows; . . Forbes Billionaires 2021 dataset publically available on Kaggle . For datasets linked to competitions, the API is present under the ‚ÄòData‚Äô tab: . . IEEE-CIS Fraud Detection competition . Finally, run the following command to download the datasets: . !kaggle datasets download -d alexanderbader/forbes-billionaires-2021-30 #or !kaggle competitions download -c ieee-fraud-detection . | . . . 7. Accessing Visual Studio Code(VS Code) on Colab üíª . Do you want to use Colab‚Äôs infrastructure without using notebooks? Then this tip might be for you. Thanks to the community‚Äôs efforts in creating a package called ColabCode. It is now possible to run VSCode in Colab. Technically it is accomplished via Code Server ‚Äî a Visual Studio Code instance running on a remote server accessible through any web browser. Detailed instructions for installing the package can be found here - https://github.com/abhi1thakur/colabcode. . Here is a quick demo of the process. . . . 8. Data Table extension üóÑ . Colab includes an extension that renders pandas‚Äô dataframes into interactive displays that can be filtered, sorted, and explored dynamically. To enable Data table display for Pandas dataframes, type in the following in the notebook cell: . %load_ext google.colab.data_table #To disable the display %unload_ext google.colab.data_table . Here is a quick demo of the same: https://colab.research.google.com/notebooks/data_table.ipynb . . . 9. Comparing Notebooks üëÄ . Colab makes it easy to compare two notebooks. Use View &gt; Diff notebooks from the Colab menu or navigate to https://colab.research.google.com/diff and paste the Colab URLs of the notebooks to be compared, in the input boxes at the top. . . . Wrap Up . These were some of the Colab tricks that I have found very useful, especially when it comes to training machine learning models on GPUs. Even though Colab notebooks can only run for at most 12 hours, nevertheless, with the hacks shared above, you should be able to make the most out of your session. .",
            "url": "https://parulnith.github.io/blog/programming/colaboratory/jupyter%20notebooks/2021/05/10/Use-Colab-more-efficiently-with-these-hacks.html",
            "relUrl": "/programming/colaboratory/jupyter%20notebooks/2021/05/10/Use-Colab-more-efficiently-with-these-hacks.html",
            "date": " ‚Ä¢ May 10, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "The curious case of Simpson‚Äôs Paradox",
            "content": "Statistics rarely offers a single ‚Äúright‚Äùway of doing anything ‚Äî Charles Wheelan in Naked Statistics . In 1996, Appleton, French, and Vanderpump* conducted an experiment to study the effect of smoking on a sample of people. The study was conducted over twenty years and included 1314 English women. Contrary to the common belief, this study showed that Smokers tend to live longer than non-smokers. Even though I am not an expert on the effects of smoking on human health, this finding is disturbing. The graph below shows that smokers had a mortality rate of 23%, while for non-smokers, it was around 31%. . . Now, here‚Äôs where the things get interesting. On breaking the same data by age group, we get an entirely different picture. The results show that in most age groups, smokers have a high mortality rate compared to non-smokers. . . So why the confusion?ü§î . Well, the phenomenon that we just saw above is a classic case of Simpson‚Äôs paradox, which from time to makes way into a lot of data-driven analysis. In this article, we‚Äôll look a little deeper into it and understand how to avoid fallacies like these in our analysis. . . Simpson‚Äôs Paradox: Things aren‚Äôt always as they seem . . As per Wikipedia, Simpson‚Äôs paradox also called the Yule-Simpson effect, can be defined as follows:* . Simpson‚Äôs Paradox is a phenomenon in probability and statistics, in which a trend appears in several different groups of data but disappears or reverses when these groups are combined. . In other words, the same data set can appear to show opposite trends depending on how it‚Äôs grouped. This is exactly what we saw in the smokers vs. non-smokers mortality rate example. When grouped age-wise, the data shows that non-smokers tend to live longer. But when we see an overall picture, smokers tend to live longer. So what is exactly happening here? Why are there different interpretations of the same data, and what is evading our eye in the first case? Well, The culprit, in this case, is called the Lurking variable ‚Äî a conditional variable **that can affect our conclusions about the relationship between two variables ‚Äî smoking and mortality in our case. . . Identifying the Lurking variable üîç . . Lurking means to be present in a latent or barely discernible state, although still having an effect. In the same way, a lurking variable is a variable that isn‚Äôt included in the analysis but, if included, can considerably change the outcome of the analysis. . The age groups are the lurking variable in the example discussed. When the data were grouped by age, we saw that the non-smokers were significantly older on average, and thus, more likely to die during the trial period, precisely because they were living longer in general. . . Try it out for yourself. üíª . Here is another example where the effect of Simpson‚Äôs Paradox is easily visible. We all are aware of the Palmer Penguinsüêß dataset ‚Äî the drop-in replacement for the famous iris dataset. The dataset consists of details about three species of penguins, including their culmen length and depth, their flipper length, body mass, and sex. The culmen is essentially the upper ridge of a penguin‚Äôs beak, while their wings are called flippers. The dataset is available for download on Kaggle. . . Attribution 1.0 Generic ([CC BY 1.0] . . Importing the necessary libraries and the dataset . import pandas as pd import seaborn as sns from scipy import stats import matplotlib.pyplot as plt %matplotlib inline #plt.rcParams[&#39;figure.figsize&#39;] = 12, 10 plt.style.use(&quot;fivethirtyeight&quot;)# for pretty graphs df = pd.read_csv(&#39;[penguins_size.csv&#39;](https://raw.githubusercontent.com/parulnith/Website-articles-datasets/master/penguins_size.csv&#39;)) df.head()&#39;) df.info() . . There are few missing values in the dataset. Let‚Äôs get rid of those. . df = df.dropna() . Let‚Äôs now visualize the relationship between the culmen length of the penguins vs. their culmen depth. We‚Äôll use seaborn‚Äôs lmplot method (where ‚Äúlm‚Äù stands for ‚Äúlinear model‚Äù)for the same. . . Here we see a negative association between culmen length and culmen depth for the data set. The results above demonstrate that the longer the culmen or the beak, the less dense it is. We have also calculated the correlation coefficient between the two columns to view the negative association using the Pearson correlation coefficient(PCC), referred to as Pearson‚Äôs r. The PCC is a number between -1 and 1 and measures the linear correlation between two data sets. The Scipy library provides a method called pearsonr() for the same. . Drilling down at Species level . When you drill down further and group the data species-wise, the findings reverse. The ‚Äòhue‚Äô parameter determines which column in the data frame should be used for color encoding. . sns.lmplot(x = &#39;culmen_length_mm&#39;,y = &#39;culmen_depth_mm&#39;, data = df, hue = &#39;species&#39;) . . Voila! What we have is a classic example of Simpson‚Äôs effect. While the culmen‚Äôs length and depth were negatively associated on a group level, the species level data exhibits an opposite association. Thus the type of species is a lurking variable here. We can also see the person‚Äôs coefficient for each of the species using the code below: . . . . Here is the nbviewer link to the notebook incase you want to follow along. . . Tools to discover Simpson‚Äôs effect üõ† . Detecting Simpson‚Äôs effect in a dataset can be tricky and requires some careful observation and analysis. However, since this issue pops up from time to time in the statistical world, few tools have been created to help us deal with it. A paper titled ‚ÄúUsing Simpson‚Äôs Paradox to Discover Interesting Patterns in Behavioral Data.‚Äù was released in 2018, highlighting a data-driven discovery method that leverages Simpson‚Äôs paradox to uncover interesting patterns in behavioral data. *The method systematically disaggregates data to identify subgroups within a population whose behavior deviates significantly from the rest of the population. *It is a great read and also has the link to the code. . . Conclusion . Data comes with a lot of power and can be easily manipulated to suit our needs and objectives. There are multiple ways of aggregating and grouping data. Depending upon how it is grouped, the data may offer confounding results. It is up to us to carefully assess all the details using the statistical tools and look for lurking variables that might affect our decisions and outcomes. . . References . This article was originally published here. . | Cover Image Photo by Brendan Church on Unsplash. . | .",
            "url": "https://parulnith.github.io/blog/statistics/2021/05/06/The-curious-case-of-Simpson-s-Paradox.html",
            "relUrl": "/statistics/2021/05/06/The-curious-case-of-Simpson-s-Paradox.html",
            "date": " ‚Ä¢ May 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "What it takes to become a World No 1 on Kaggle",
            "content": ". In this series of interviews, I present the stories of established Data Scientists and Kaggle Grandmasters at H2O.ai, who share their journey, inspirations, and accomplishments. The intention behind these interviews is to motivate and encourage others who want to understand what it takes to be a Kaggle Grandmaster. . In this article, I shall be sharing my interaction with Guanshuo Xu. **He is a **Kaggle Competitions Grandmaster and a Data Scientist at H2O.ai**. Guanshuo obtained his Ph.D. in Electrical &amp; Electronics Engineering at the New Jersey Institute of Technology, focusing on machine learning-based image forensics and steganalysis. . Guanshuo is a man of many accomplishments. His methods for real-world image tampering detection and localization won second place in the First IEEE Image Forensics Challenge**. His architectural design of deep neural networks outperformed traditional feature-based methods for the first time in image steganalysis. More recently, Guanshuo also achieved the world rank #1 in the competition‚Äôs tier on Kaggle with a win in the Alaska2 Image Steganalysis and RSNA STR Pulmonary Embolism Detection competitions. . Here is also a link to Guanshuo‚Äôs interview at CTDS.show where he discusses his achievements on Kaggle. . In this interview, we shall know more about his academic background, passion for Kaggle, and his journey to the number one title. Here is an excerpt from my conversation with Gunashuo: . You have a background in Ph.D. in Electrical Engineering. Did it somehow influence your decision to take up Machine Learning as a career? . Guanshuo: Yes, my doctoral research used machine learning techniques to solve problems like image tampering detection and hidden data detection. For example, my last Ph.D. research project was to use deep neural nets on image steganalysis. So my education and research are directly related to machine learning. Hence, machine learning was a natural choice of career for me. . How did your tryst with Kaggle begin, and what kept you motivated throughout your grandmaster‚Äôs journey? . Gunahuo‚Äôs Kaggle Profile . Guanshuo: From the time I discovered kaggle, I have been addicted to it. Some of the motivating factors for continuous competing on Kaggle would be the combined satisfaction of winning competitions and prize money, learning new techniques, widening and deepening my understanding of machine learning, and building surprisingly effective models. . How does it feel to be World No 1 in Competitions? Does that bring in an extra amount of pressure while competing? . . The top 5 Kagglers in the Competition‚Äôs category as on date | Source: Kaggle‚Äôs website . Guanshuo: Honestly speaking, there is a lot more pressure to maintain the number one rank than achieve it. This is because it requires ‚Äúsmoother‚Äù performance. Sometimes I have to participate in more competitions simultaneously than I used to participate in before. . How do you typically approach a Kaggle problem? . A glimpse of Gunashuo‚Äôs wins on Kaggle . Guanshuo: My approach varies based on the type of problem and the goal of the competition. Nowadays, what I often do is spend days or even weeks on understanding the data and the problem and thinking of a solution which includes, for instance, guessing the distribution of the private test data, proper validation scheme, detailed modeling steps, etc. Once I have a decent picture of the overall approach, I start coding and modeling. This process helps me to gain more understanding and make corrections or adjustments, if necessary, to the overall approach. . Could you give us a sneak peek into your toolkit like a favorite programming language, IDE, Algorithms, etc . Guanshuo: As far as my toolkit is concerned, I mostly use gedit, Python, and Pytorch for deep learning. . The Data Science domain is rapidly evolving. How do you manage to keep up with all the latest developments? . Guanshuo: I get to know about most of the new stuff and technologies through Kaggle, my colleagues, or even by mere googling. As far as new developments in machine learning are concerned, it depends on the actual needs. I tend to filter out anything not instantly helpful and maybe keep an eye on the potentially exciting stuff. Then I get back to it as and when needed. . A word of advice for the Data Science aspirants who have just started or wish to start their Data Science journey? . . Guanshuo: It basically depends on each person‚Äôs background and interests. However, finding a suitable platform to learn and develop skills can make things much easier in general. Additionally, taking part in Kaggle competitions can prove to be an additional helpful resource. . To achieve a world no 1 rank is no mean feat, and Guanshuo‚Äôs relentless attitude and hard work deserve all the credit. A peek into his various winning solutions on Kaggle showcases his structured approach, which is an essential element to be inculcated for problem-solving. . Read other interviews in this series: . [Rohan Rao: A Data Scientist‚Äôs journey from Sudoku to Kaggle](https://towardsdatascience.com/a-data-scientists-journey-from-sudoku-to-kaggle-120876b7fa33) . | [Shivam Bansal: The Data Scientist who rules the ‚ÄòData Science for Good‚Äô competitions on Kaggle.](https://towardsdatascience.com/the-data-scientist-who-rules-the-data-science-for-good-competitions-on-kaggle-ab436595a29f) . | [Meet Yauhen: The first and the only Kaggle Grandmaster from Belarus.](https://towardsdatascience.com/meet-yauhen-the-first-and-the-only-kaggle-grandmaster-from-belarus-ee6ae3c86c65) . | [Sudalai Rajkumar: How a passion for numbers turned this Mechanical Engineer into a Kaggle Grandmaster](https://towardsdatascience.com/how-a-passion-for-numbers-turned-this-mechanical-engineer-into-a-kaggle-grandmaster-8b1ae218afc) . | [Gabor Fodor: The inspiring journey of the ‚ÄòBeluga‚Äô of Kaggle World üêã](https://towardsdatascience.com/the-inspiring-journey-of-the-beluga-of-kaggle-world-5409e740a21b?sk=a500e2014feb175eae520931ff43b419) . | [Meet the Data Scientist who just cannot stop winning on Kaggle](https://towardsdatascience.com/meet-the-data-scientist-who-just-cannot-stop-winning-on-kaggle-dfc0e6fe88f8?sk=bd58ca871ab26ab13917b338020c4a0c) . | [Learning from others is imperative to success on Kaggle says this Turkish GrandMaster](https://towardsdatascience.com/learning-from-others-is-imperative-to-success-on-kaggle-says-this-turkish-grandmaster-d8b5bf28ac87?sk=940c646515035c18aca050bab1469364) . | . Originally published at H2O.ai blog .",
            "url": "https://parulnith.github.io/blog/kaggle/interviews/2021/05/03/What-it-takes-to-become-a-World-No-1-on-Kaggle.html",
            "relUrl": "/kaggle/interviews/2021/05/03/What-it-takes-to-become-a-World-No-1-on-Kaggle.html",
            "date": " ‚Ä¢ May 3, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! I‚Äôm Parul and I work at H2O.ai .",
          "url": "https://parulnith.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://parulnith.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}